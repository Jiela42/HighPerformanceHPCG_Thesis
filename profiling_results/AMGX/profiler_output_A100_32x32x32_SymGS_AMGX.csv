AMGX,A100,32x32x32,SymGS
"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description"
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8445",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.97",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.35",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.97",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.08",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.91",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","3017.48",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.20",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.42",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.34",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.25",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.34",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","125.27",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.97",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.35",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.77",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","32.07",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.64",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.27",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.73",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.94",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.94 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.79",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.12",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.10",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.82",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.9% of the total average of 30.8 cycles between issuing two instructions."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","878.97",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","379715",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","945.66",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","408524",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11403 fused and 8869 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.06",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.72",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41776",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.87",
"0","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7785 excessive sectors (20% of the total 38969 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8215",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.25",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.59",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.87",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.15",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","9.53",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","3145.88",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.56",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 1% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.12",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.43",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.16",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.21",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.16",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (21.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","127.46",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.25",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.59",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.05",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.50",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.88",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.40",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.60",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.97",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.97 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.78",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.13",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.08",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.79",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.3 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 33.4% of the total average of 30.8 cycles between issuing two instructions."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","881.59",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","380845",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","948.88",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","409915",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11493 fused and 8939 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 35.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","63.09",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.38",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (63.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41936",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.91",
"1","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7810 excessive sectors (20% of the total 39229 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8138",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.16",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.49",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.65",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.05",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","9.04",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2972.13",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.48",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.43",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.38",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.38",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","128.18",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.16",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.49",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.95",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.42",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.82",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.07",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.93",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.02",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.02 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.29",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.62",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.26",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.98",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.7% of the total average of 30.3 cycles between issuing two instructions."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","866.15",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","374178",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","932.79",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","402965",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 10962 fused and 8526 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.54",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.03",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","40992",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.64",
"2","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7696 excessive sectors (20% of the total 38040 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.13",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8121",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.24",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.59",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.97",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.10",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","9.32",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2986.58",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.55",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 1% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.43",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.39",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.39",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","124.37",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.24",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.59",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.42",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.43",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.86",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.35",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.65",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.93",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.93 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.70",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.05",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.22",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.93",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.3% of the total average of 30.7 cycles between issuing two instructions."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","870.60",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","376099",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","937.45",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","404977",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11115 fused and 8645 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.00",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.68",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41264",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.72",
"3","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7785 excessive sectors (20% of the total 38520 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8028",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.85",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.96",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.84",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.42",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2859.18",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.20",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.42",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.43",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.43",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","116.41",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.85",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.07",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.00",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.82",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.62",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.90",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.10",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.93",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.93 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.17",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.51",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.58",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.32",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 30.3% of the total average of 30.2 cycles between issuing two instructions."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","833.98",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","360279",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","898.67",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","388225",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9855 fused and 7665 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.63",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.44",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","39024",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.07",
"4","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6793 excessive sectors (20% of the total 34163 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8240",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.54",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.62",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.90",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.16",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2825.15",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.83",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.59",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.59",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","114.75",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.54",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.80",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.84",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.71",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.36",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.86",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.14",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.30",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.65",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.64",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.38",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","827.96",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","357680",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","892.32",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","385484",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9648 fused and 7504 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.14",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.77",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38656",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.96",
"5","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6640 excessive sectors (20% of the total 33384 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8200",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.49",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.50",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.90",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.07",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.04",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2774.69",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.79",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.87",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.87",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","110.41",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.49",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.75",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.12",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.94",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.34",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.01",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.99",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.97",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.97 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.20",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.54",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.71",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.46",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","820.64",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","354516",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","884.23",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","381988",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9396 fused and 7308 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.38",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.92",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38208",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.83",
"6","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6322 excessive sectors (20% of the total 32346 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8260",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.46",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.51",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.84",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.83",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.13",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2930.94",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.75",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.12",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.28",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.21",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.28",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","112.28",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.46",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.73",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.18",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.27",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.31",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","30.74",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.31",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","69.26",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.31",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.65",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.31 active warps per scheduler, but only an average of 0.65 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","33.54",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","36.14",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.68",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.42",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","823.78",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","355872",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","887.58",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","383434",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9504 fused and 7392 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 35.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","63.75",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.80",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (63.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38400",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.89",
"7","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6401 excessive sectors (20% of the total 32692 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8109",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.44",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.41",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.87",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.94",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.19",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2743.29",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.78",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.85",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.85",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","108.11",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.44",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.73",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.45",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.51",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.33",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.06",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.94",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.12",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.47",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.82",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.57",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","810.44",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","350109",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","873.63",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","377410",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9045 fused and 7035 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.34",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.90",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37584",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.65",
"8","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6240 excessive sectors (20% of the total 31250 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8238",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.37",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.34",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.84",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.91",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.02",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2764.71",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.66",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.73",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.73",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","109.39",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.37",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.65",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.16",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.10",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.24",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.88",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.12",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.17",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.52",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.79",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.54",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","813.84",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","351578",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","877.30",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","378992",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9162 fused and 7126 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.84",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.58",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37792",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.71",
"9","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6541 excessive sectors (20% of the total 31954 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8254",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.20",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.11",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.96",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.50",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2711.97",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.50",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.94",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.94",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","109.29",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.20",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.53",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.19",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.78",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.13",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.77",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.23",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.90",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.90 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.22",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.57",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.89",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.64",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","803.64",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","347171",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","866.09",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","374151",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8811 fused and 6853 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.92",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.63",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37168",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.53",
"10","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6164 excessive sectors (20% of the total 30483 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8254",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.34",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.31",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.92",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.86",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2757.62",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.62",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.74",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.74",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","111.09",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.34",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.62",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.49",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.58",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.22",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.82",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.18",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.91",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.91 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.19",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.53",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.81",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.55",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","812.27",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","350900",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","875.25",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","378109",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9108 fused and 7084 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.05",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.71",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37696",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.69",
"11","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6300 excessive sectors (20% of the total 31557 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.13",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8058",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.20",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.95",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.87",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.83",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.38",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2661.03",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.55",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.95",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.95",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.83",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.20",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.55",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.21",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.45",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.17",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.21",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.79",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.00",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.33",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.06",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.83",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","788.73",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","340730",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","850.08",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","367233",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8298 fused and 6454 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.13",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.76",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36256",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.27",
"12","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5767 excessive sectors (20% of the total 28779 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8092",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.31",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.12",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.87",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.93",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.57",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2696.19",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.66",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.97",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.97",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.82",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.31",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.63",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.55",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.81",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.24",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.13",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.87",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.99",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.99 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.15",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.51",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.95",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.70",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","799.45",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","345363",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","862.05",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","372406",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8667 fused and 6741 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.24",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.83",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36912",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.46",
"13","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6132 excessive sectors (20% of the total 30180 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8159",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.09",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.85",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.97",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.97",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.24",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2873.59",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.41",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.10",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","29.53",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.18",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","29.53",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (21.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","99.52",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.09",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.45",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.48",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.38",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.07",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.30",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.70",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.94",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.94 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.84",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.17",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.10",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.86",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","787.16",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","340052",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","848.69",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366636",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8244 fused and 6412 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 34.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","64.55",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","41.31",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (64.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36160",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.24",
"14","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6040 excessive sectors (21% of the total 29046 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8253",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.04",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.83",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.68",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.09",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2686.45",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.35",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.75",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.75",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.34",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.04",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.40",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.62",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.42",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.03",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.14",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.86",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.89",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.89 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.85",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.18",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.03",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.79",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","791.34",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","341860",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","853.08",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","368530",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8388 fused and 6524 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.69",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.48",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36416",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.31",
"15","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5809 excessive sectors (20% of the total 29021 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8073",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.16",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.90",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.55",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.77",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.30",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2657.58",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.51",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.91",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.91",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","104.54",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.16",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.52",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.28",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.44",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.14",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.79",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.21",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.94",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.94 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.31",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.68",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.10",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.86",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","786.37",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","339713",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","847.99",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366333",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8217 fused and 6391 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.96",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.66",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36112",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.23",
"16","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5936 excessive sectors (21% of the total 28764 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7984",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.20",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.84",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.68",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.30",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2650.26",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.57",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.82",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.82",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","99.92",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.20",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.54",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.47",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.50",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.17",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.28",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.72",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.89",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.89 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.71",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.03",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.14",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.91",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","782.19",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337905",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","843.36",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364330",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8073 fused and 6279 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.77",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.53",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35856",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.15",
"17","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5656 excessive sectors (20% of the total 28075 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8079",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.10",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.81",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.72",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.39",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2645.37",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.43",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.86",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.86",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","101.75",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.10",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.46",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.90",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.68",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.09",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.37",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.63",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.72",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.03",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.16",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.92",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","781.93",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337792",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","842.73",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364060",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8064 fused and 6272 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.82",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.56",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35840",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.15",
"18","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5829 excessive sectors (21% of the total 28315 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8376",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.83",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.57",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.68",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.98",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2655.22",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.09",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.80",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.80",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","99.67",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.83",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.21",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.43",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.38",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.85",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.87",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.13",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.98",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.98 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.35",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.72",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.13",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.90",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","783.23",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","338357",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","844.31",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364744",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8109 fused and 6307 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.81",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.56",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35920",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.17",
"19","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5671 excessive sectors (20% of the total 28177 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8317",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.80",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.47",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.71",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.89",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2624.41",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.09",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.93",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.93",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.6%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","98.24",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.80",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.20",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.34",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.89",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.85",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.08",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.92",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.10",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.46",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.20",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.97",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","776.96",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","335645",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","838.04",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","362034",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7893 fused and 6139 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.24",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.83",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35536",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.06",
"20","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5448 excessive sectors (20% of the total 27372 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8380",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.93",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.75",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.56",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.12",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2704.18",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.18",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.54",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.54",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.26",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.93",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.29",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.24",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.31",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.92",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.91",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.09",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.87",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.87 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.98",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.33",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.05",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.81",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","791.08",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","341747",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","852.92",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","368463",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8379 fused and 6517 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.47",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.34",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36400",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.31",
"21","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5993 excessive sectors (20% of the total 29324 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8219",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.93",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.67",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.74",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.59",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.27",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2649.70",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.24",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.74",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.74",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.63",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.93",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.31",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.96",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.84",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.95",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","30.66",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.31",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","69.34",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.28",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.64",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.3 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.28 active warps per scheduler, but only an average of 0.64 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","33.53",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","36.15",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.18",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.94",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","780.09",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337001",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","841.08",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","363346",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8001 fused and 6223 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.78",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.54",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35728",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.12",
"22","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5468 excessive sectors (20% of the total 27767 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8269",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.97",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.79",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.84",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.66",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.22",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2671.07",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.26",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.74",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.74",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","101.53",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.97",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.34",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.46",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.08",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.97",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.24",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.76",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.94",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.94 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.92",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.25",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.10",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.87",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","786.37",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","339713",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","847.76",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366232",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8217 fused and 6391 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.87",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.60",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36112",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.23",
"23","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5882 excessive sectors (20% of the total 28770 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.22",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.10",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8429",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.73",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.46",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.69",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.94",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2640",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.98",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.86",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.86",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.57",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.73",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.12",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.94",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.07",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.78",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","31.86",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","68.14",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.03",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.66",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.03 active warps per scheduler, but only an average of 0.66 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.50",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.96",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.17",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.94",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","780.09",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337001",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","841.23",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","363411",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8001 fused and 6223 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.54",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.39",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35728",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.12",
"24","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5514 excessive sectors (20% of the total 27778 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8178",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.93",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.64",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.93",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.03",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2599.98",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.24",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.20",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.20",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.8%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.42",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.93",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.31",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.19",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.78",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.95",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.19",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.81",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.95",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.95 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.98",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.32",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.22",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.00",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","776.43",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","335419",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","837.26",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","361695",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7875 fused and 6125 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.33",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.89",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35504",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.05",
"25","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5754 excessive sectors (21% of the total 27759 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.13",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8091",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.98",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.63",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.94",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.73",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.95",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2611",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.32",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.96",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.96",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","95.95",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.98",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.36",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.36",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.23",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.00",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.43",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.57",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.93",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.93 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.71",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.03",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.26",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.03",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","773.82",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","334289",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","834.46",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","360486",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7785 fused and 6055 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.75",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.52",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35344",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.00",
"26","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5643 excessive sectors (21% of the total 27428 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8095",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.80",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.34",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.55",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.76",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.46",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2548.47",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.13",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.15",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.15",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","96.61",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.80",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.22",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.88",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.01",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.87",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.13",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.87",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.88",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.88 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.81",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.15",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.44",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.22",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","759.69",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","328187",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","819.34",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","353956",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7299 fused and 5677 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.74",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.51",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","34480",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.75",
"27","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5410 excessive sectors (21% of the total 25901 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8242",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.58",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.11",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.64",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.34",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2534.70",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.87",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.07",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.07",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","93.98",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.58",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.03",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.37",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.69",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.69",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.66",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.34",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.90",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.90 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.40",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.73",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.53",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.31",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 30.5% of the total average of 29.4 cycles between issuing two instructions."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","753.41",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","325475",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","812.97",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","351201",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7083 fused and 5509 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.05",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.71",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","34096",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.64",
"28","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5372 excessive sectors (21% of the total 25399 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8128",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.52",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","5.87",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.32",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.10",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2511.09",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.85",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.36",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.86",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.86",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","88.89",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.52",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.99",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.99",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.69",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.67",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.21",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.79",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.88",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.88 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.75",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.11",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.68",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.47",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.1 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 30.5% of the total average of 29.7 cycles between issuing two instructions."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","741.12",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","320164",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","800.10",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","345642",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 6660 fused and 5180 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.87",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.59",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","33344",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.43",
"29","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4903 excessive sectors (21% of the total 23693 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7994",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.42",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","5.60",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.39",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","5.77",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2429.71",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.79",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.36",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.19",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.19",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","83.48",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.42",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.93",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.57",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.80",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.63",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.84",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.16",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.83",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.83 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.06",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.39",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.92",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.72",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 32.2% of the total average of 29.1 cycles between issuing two instructions."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","724.12",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","312819",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","782.13",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","337881",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 6075 fused and 4725 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.22",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.18",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","32304",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.12",
"30","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4602 excessive sectors (21% of the total 21897 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8113",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.08",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","5.09",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.32",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","4.99",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2360.49",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.42",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.20",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.35",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.38",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.30",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.38",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","76.84",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.08",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.64",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.85",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.73",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.37",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.75",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.25",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.85",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.85 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.18",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.54",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.14",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.97",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 33.0% of the total average of 29.2 cycles between issuing two instructions."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","707.12",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","305474",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","764.27",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","330165",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 5490 fused and 4270 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.16",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.14",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","31264",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.82",
"31","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4129 excessive sectors (21% of the total 19739 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8035",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.82",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","4.46",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.10",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","4.38",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2270.67",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.19",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.20",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.34",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.51",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.30",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.51",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","65.88",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.82",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.43",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.31",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.00",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.21",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.09",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.91",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.81",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.81 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","28.77",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.11",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.51",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.35",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 13.1 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 45.5% of the total average of 28.8 cycles between issuing two instructions."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","682.53",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","294852",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","738.25",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","318925",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 4644 fused and 3612 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.15",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.13",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","29760",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.39",
"32","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 3438 excessive sectors (21% of the total 16704 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8120",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.45",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","3.82",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.65",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.06",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","3.77",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2173.93",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.81",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.21",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.88",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.32",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.88",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","57.76",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.45",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.14",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.25",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.50",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.94",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.24",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.76",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.78",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.78 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","28.56",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.92",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.85",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.71",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 35.1% of the total average of 28.6 cycles between issuing two instructions."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","660.29",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","285247",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","714.77",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","308779",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 3879 fused and 3017 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.21",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.17",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","28400",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.00",
"33","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2956 excessive sectors (21% of the total 14042 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8305",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.08",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","3.27",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.96",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","3.25",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2106.42",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.22",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.11",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.32",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.11",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (26.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","50.23",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.08",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.82",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.86",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.43",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.66",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.65",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.35",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.83",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.83 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","28.36",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.72",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.11",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","30.00",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.5 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 36.9% of the total average of 28.4 cycles between issuing two instructions."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","643.81",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","278128",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","697.45",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","301300",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 3312 fused and 2576 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.66",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.46",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","27392",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.70",
"34","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2619 excessive sectors (22% of the total 12087 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7935",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.04",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","2.71",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.49",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.63",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","2.65",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2026.31",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.48",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.22",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.18",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.33",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.18",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (26.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","40.79",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.04",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.83",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.63",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.23",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.70",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.89",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.11",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.76",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.67",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.76 active warps per scheduler, but only an average of 0.67 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.98",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.33",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.52",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","30.43",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 38.0% of the total average of 28.0 cycles between issuing two instructions."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","620.27",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","267958",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","672.39",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","290473",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 2502 fused and 1946 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.21",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.18",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","25952",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.29",
"35","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2000 excessive sectors (22% of the total 9158 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7862",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.91",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","2.28",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.49",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.25",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","2.26",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1996.05",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.38",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.22",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.98",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.32",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.98",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (26.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","33.95",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.91",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.74",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.50",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","32.27",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.63",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.88",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.12",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.71",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.67",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.71 active warps per scheduler, but only an average of 0.67 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.85",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.20",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.76",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","30.68",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 39.1% of the total average of 27.9 cycles between issuing two instructions."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","607.19",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","262308",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","658.30",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","284386",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 2052 fused and 1596 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.71",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.85",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","25152",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.06",
"36","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 1695 excessive sectors (22% of the total 7568 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7793",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.71",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","1.66",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.30",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.28",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","1.73",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1909.45",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.21",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.23",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.50",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.34",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.50",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","25.16",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.71",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.59",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","20.94",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","35.88",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.51",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.49",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.51",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.78",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.78 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.57",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.92",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.11",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.05",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.2 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 40.7% of the total average of 27.6 cycles between issuing two instructions."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","589.41",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","254624",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","639.61",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","276310",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 1440 fused and 1120 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.98",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.03",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","24064",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.74",
"37","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 1162 excessive sectors (22% of the total 5297 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7809",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.56",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","1.30",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.39",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.26",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","1.21",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1864.53",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.05",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.71",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.71",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.6%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","19.50",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.56",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.46",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","20.70",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","40.91",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.41",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.98",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.02",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.83",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.83 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.33",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.64",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.31",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.27",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 41.6% of the total average of 27.3 cycles between issuing two instructions."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","579.47",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","250330",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","628.55",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","271535",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 1098 fused and 854 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.24",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.19",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","23456",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.56",
"38","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 938 excessive sectors (23% of the total 4105 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7808",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.41",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.90",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.36",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.35",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.86",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1808.07",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","7.91",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.26",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.29",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","34.14",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.37",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","34.14",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","13.50",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.41",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.34",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","19.55",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","47.02",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.31",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.93",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.07",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.80",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.80 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.28",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.60",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.53",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.50",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 42.5% of the total average of 27.3 cycles between issuing two instructions."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","569.00",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","245810",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","617.36",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","266700",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 738 fused and 574 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.28",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.22",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","22816",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.38",
"39","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 573 excessive sectors (21% of the total 2685 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7933",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.25",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.67",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.49",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.00",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.69",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1807.98",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","7.72",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.28",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.83",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.83",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","10.10",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.25",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.20",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","18.72",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","52.91",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.17",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.6 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.75",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.25",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.70",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.70 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.13",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.45",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.65",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.63",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 14.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 54.0% of the total average of 27.1 cycles between issuing two instructions."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","563.25",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","243324",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","611.59",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","264208",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 540 fused and 420 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.86",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.95",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","22464",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.28",
"40","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 440 excessive sectors (22% of the total 1990 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7350",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.52",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.34",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","6.91",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.82",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.36",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1778.04",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.19",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.84",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.84",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","5.07",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.52",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.50",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","15.72",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","67.69",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.49",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.10",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.90",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.70",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.70 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.88",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.17",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.85",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.84",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 13.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 49.8% of the total average of 26.9 cycles between issuing two instructions."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","554.36",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","239482",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","601.65",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","259911",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 234 fused and 182 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.51",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.73",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21920",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.12",
"41","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 233 excessive sectors (26% of the total 909 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.08",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","981.08",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6885",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.84",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.14",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.01",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.67",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.24",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1769.98",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.68",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.32",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.73",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.73",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","1.90",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.84",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.83",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","15.31",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","83.91",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.82",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.6 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.87",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.13",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.68",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.68 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.00",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.30",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.94",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.94",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 12.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.4% of the total average of 27.0 cycles between issuing two instructions."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","550.17",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","237674",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","597.04",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","257921",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 90 fused and 70 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.42",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.67",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21664",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.05",
"42","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 67 excessive sectors (21% of the total 322 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.12",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6650",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.05",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","6.59",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.65",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.21",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1763.60",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.96",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.76",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.76",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","757.28",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","17.14",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","90.34",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.76",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.24",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.66",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.66 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.01",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.31",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.98",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.97",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 12.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.3% of the total average of 27.0 cycles between issuing two instructions."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","548.60",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","236996",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","595.46",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","257240",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 36 fused and 28 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.27",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.58",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21568",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.02",
"43","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 36 excessive sectors (26% of the total 140 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.04",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","942.41",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6608",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.04",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.03",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.01",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.65",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.21",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1761.45",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.01",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.77",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.77",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","383.56",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.04",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.04",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","13.64",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","92.64",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.04",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.17",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.83",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.74",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.74 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.93",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.23",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.99",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.99",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 12.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.4% of the total average of 26.9 cycles between issuing two instructions."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","548.08",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","236770",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","594.92",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","257004",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 18 fused and 14 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.47",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.70",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21536",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.01",
"44","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 14 excessive sectors (21% of the total 66 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.04",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","932.21",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","5969",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.68",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.02",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","6.40",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.68",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.22",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1757.06",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.97",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.84",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.84",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","220",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.68",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.68",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","13.33",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","94.32",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.68",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.20",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.80",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.75",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.75 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.94",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.24",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.99",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.99",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.2% of the total average of 26.9 cycles between issuing two instructions."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","547.82",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","236657",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","594.65",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","256887",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9 fused and 7 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.62",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.80",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21520",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.00",
"45","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4 excessive sectors (13% of the total 30 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.09",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","979.70",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6183",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.47",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.02",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","6.30",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.82",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.21",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1750.86",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.63",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.35",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.97",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.36",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.97",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","223.35",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.47",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.45",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","13.33",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","94.42",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.45",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.4 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.29",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.71",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.77",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.77 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.92",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.23",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.99",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.99",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 13.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 51.0% of the total average of 26.9 cycles between issuing two instructions."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","547.82",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","236657",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","594.74",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","256927",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9 fused and 7 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.66",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.82",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21520",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.00",
"46","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4 excessive sectors (13% of the total 30 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.05",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","946.59",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6637",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.02",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.65",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.21",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1760.79",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.97",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.79",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.79",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","328.77",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","13.64",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","92.49",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.12",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.88",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.71",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.71 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.89",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.18",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.98",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.98",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.2% of the total average of 26.9 cycles between issuing two instructions."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","548.16",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","236806",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","594.96",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","257022",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 25 fused and 18 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 21% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.48",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.71",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21541",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","81.82",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.01",
"47","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 14 excessive sectors (21% of the total 66 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.06",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","954.13",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","6570",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.08",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.05",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","6.88",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","20.42",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.21",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1955.92",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.07",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.12",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.44",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.22",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.44",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Mbyte/second","725.58",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.08",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.08",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","17.14",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","91.36",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.08",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.86",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.14",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.66",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.66 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.94",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.23",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.97",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.97",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.3% of the total average of 26.9 cycles between issuing two instructions."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","548.69",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","237032",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","595.47",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","257244",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 43 fused and 32 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 21% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 34.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","64.21",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","41.09",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (64.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21573",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","80",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.02",
"48","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 36 excessive sectors (26% of the total 140 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.07",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/usecond","965.78",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7110",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.65",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.14",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.36",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.84",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.23",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1756.89",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.40",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","34.00",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.36",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","34.00",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","1.86",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.65",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.63",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","15.31",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","83.96",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.63",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.6 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.01",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.99",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.67",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.67 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.84",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.14",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.93",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.93",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.8 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 44.0% of the total average of 26.8 cycles between issuing two instructions."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","550.25",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","237710",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","597.28",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","258027",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 97 fused and 74 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.53",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.74",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21669",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.72",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.05",
"49","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 67 excessive sectors (21% of the total 322 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7464",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.44",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.33",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.30",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.81",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.36",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1778.94",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.07",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.84",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.35",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.84",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","4.81",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.44",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.42",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","15.81",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","67.60",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.41",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","36.03",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","63.97",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.72",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.72 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","26.99",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.29",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.83",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.82",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 43.4% of the total average of 27.0 cycles between issuing two instructions."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","554.69",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","239626",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","602.03",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","260079",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 262 fused and 198 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.66",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.82",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","21940",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","79.20",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.12",
"50","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 233 excessive sectors (26% of the total 909 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7865",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.29",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.68",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.42",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","22.83",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.70",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1821.33",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","7.78",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.29",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.59",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.34",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.59",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.8%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","10.16",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.29",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.24",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","18.75",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","52.91",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.21",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.6 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.67",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.33",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.70",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.70 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.19",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.51",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.62",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.60",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 43.1% of the total average of 27.2 cycles between issuing two instructions."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","563.75",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","243540",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","611.71",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","264257",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 582 fused and 444 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.56",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.76",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","22494",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.72",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.28",
"51","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 440 excessive sectors (22% of the total 1990 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8012",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.27",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","0.87",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.65",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.19",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","0.85",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1820.82",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","7.72",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.28",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.95",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.36",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.95",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (28.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","12.94",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.27",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.21",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","19.63",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","47.19",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.17",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.91",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.09",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.78",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.78 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.22",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.54",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.49",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.46",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 42.0% of the total average of 27.2 cycles between issuing two instructions."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","569.59",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","246062",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","618.08",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","267012",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 787 fused and 602 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.63",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.44",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","22851",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.59",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.38",
"52","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 573 excessive sectors (21% of the total 2685 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7850",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.53",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","1.28",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.58",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.36",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","1.20",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1856.59",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.02",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.25",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.89",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.36",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.89",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","18.90",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.53",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.44",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","20.60",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","41.10",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.38",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.73",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.27",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.83",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.83 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.52",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.85",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.28",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.24",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 40.9% of the total average of 27.5 cycles between issuing two instructions."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","579.97",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","250546",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","629.19",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","271809",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 1140 fused and 878 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.34",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.26",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","23486",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.25",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.56",
"53","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 938 excessive sectors (23% of the total 4105 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.12",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.01",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7921",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.61",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","1.64",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.84",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.29",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","1.70",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1908.29",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.08",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.24",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.53",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.34",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.53",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (27.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","23.43",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.61",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.50",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","20.91",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","35.76",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.42",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.50",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.36",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.50",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.75",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.75 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.46",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","29.78",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","31.07",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","31.02",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.2 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 40.9% of the total average of 27.5 cycles between issuing two instructions."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","590.07",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","254912",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","639.90",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","276438",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 1496 fused and 1152 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.96",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.02",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.09",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","24104",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.26",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","0.74",
"54","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 1162 excessive sectors (22% of the total 5297 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","7980",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.82",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","2.24",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.39",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","2.21",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","1983.54",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.27",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.23",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.30",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.26",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.33",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.26",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (26.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","33.12",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.82",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.65",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.51",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","32.04",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.55",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","35.22",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","64.78",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.75",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.8 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.75 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.67",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.02",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.72",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","30.64",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 39.3% of the total average of 27.7 cycles between issuing two instructions."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","608.11",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","262704",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","659.67",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","284978",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 2129 fused and 1640 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.71",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.86",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","25207",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.24",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.06",
"55","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 1695 excessive sectors (22% of the total 7568 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8012",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","5.98",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","2.68",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.58",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","2.63",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2030.11",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.22",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","33.17",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.33",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","33.17",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (26.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","39.54",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","5.98",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.77",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.60",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.01",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.65",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.96",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.04",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.75",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.75 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","27.90",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.25",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.48",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","30.39",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.6 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 38.0% of the total average of 27.9 cycles between issuing two instructions."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","621.11",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","268318",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","673.44",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","290926",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 2572 fused and 1986 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.98",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.03",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","26002",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.13",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.29",
"56","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2000 excessive sectors (22% of the total 9158 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8315",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.07",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","3.27",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.75",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","3.23",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2124.36",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.41",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.22",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.31",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.92",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.32",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.92",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","49.66",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.07",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","5.81",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","21.86",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.20",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","5.65",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.74",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.35",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.26",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.82",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.82 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","28.26",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.60",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","30.03",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.91",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 36.5% of the total average of 28.3 cycles between issuing two instructions."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","645.73",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","278956",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","699.26",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","302079",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 3473 fused and 2668 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.9%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.17",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.15",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","27507",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.38",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","1.70",
"57","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2619 excessive sectors (22% of the total 12087 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8037",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.51",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","3.88",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.65",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.77",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","3.80",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2199.01",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","8.92",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.20",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.58",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.30",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.58",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","57.77",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.51",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.19",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.27",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.61",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.00",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","34.27",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","65.73",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.78",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 2.9 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.78 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","28.54",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","30.90",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.77",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.64",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.1 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 35.3% of the total average of 28.5 cycles between issuing two instructions."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","661.96",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","285967",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","716.50",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","309527",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 4019 fused and 3097 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.90",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.98",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","28500",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.23",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.00",
"58","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 2956 excessive sectors (21% of the total 14042 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8215",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.67",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","4.36",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.94",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.03",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","4.30",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2277.21",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.01",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.20",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.47",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.30",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.47",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (25.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","64.03",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.67",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.29",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.35",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.07",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.07",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.19",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.81",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.10",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.64",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.10 active warps per scheduler, but only an average of 0.64 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","31.38",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.94",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.46",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","29.30",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.7 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 34.2% of the total average of 31.4 cycles between issuing two instructions."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","683.61",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","295320",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","739.37",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","319409",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 4735 fused and 3664 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.89",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.97",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","29825",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.02",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.39",
"59","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 3438 excessive sectors (21% of the total 16704 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8475",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","6.78",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","4.87",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.13",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","4.79",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2378.18",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.04",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.33",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.21",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.21",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","74.95",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","6.78",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.36",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.81",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.77",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.10",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.81",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.19",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.81",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.81 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.02",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.36",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","29.08",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.90",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.4 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 32.5% of the total average of 29.0 cycles between issuing two instructions."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","708.78",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","306194",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","765.91",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","330874",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 5630 fused and 4350 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.94",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.00",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","31364",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.10",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","2.82",
"60","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4129 excessive sectors (21% of the total 19739 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.13",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.02",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8088",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.33",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","5.55",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.90",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.30",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","5.72",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2437.44",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.69",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.36",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.14",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.14",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","80.58",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.33",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.84",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.60",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.83",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.55",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.60",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.40",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.83",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.83 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.25",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.58",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.87",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.68",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.3 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 31.7% of the total average of 29.2 cycles between issuing two instructions."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","725.37",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","313359",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","783.28",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","338377",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 6180 fused and 4785 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 38.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","60.92",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","38.99",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (60.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","32379",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","78.00",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.12",
"61","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4602 excessive sectors (21% of the total 21897 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8243",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.41",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","5.79",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.02",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.02",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2652.09",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.73",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.12",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.36",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.21",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.21",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.21",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","87.16",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.41",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.89",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.04",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.64",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.58",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.57",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.43",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.87",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.87 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.41",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.75",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.63",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.43",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 8.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 30.4% of the total average of 29.4 cycles between issuing two instructions."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","742.29",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","320668",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","801.21",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","346121",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 6758 fused and 5236 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 35.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","63.42",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.59",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (63.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","33414",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.96",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.43",
"62","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 4903 excessive sectors (21% of the total 23693 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8328",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.50",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.07",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.69",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.28",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2529.51",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.78",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.36",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.18",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.29",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.18",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (24.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","91.66",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.50",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","6.95",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.36",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.69",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.62",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.55",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.34",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.45",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.57",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","31.91",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.50",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.28",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 8.9 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 30.0% of the total average of 29.6 cycles between issuing two instructions."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","754.25",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","325835",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","813.92",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","351612",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7153 fused and 5549 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.93",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.64",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.10",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","34146",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.90",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.64",
"63","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5372 excessive sectors (21% of the total 25399 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8218",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.68",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.25",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.90",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.51",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.37",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2574.88",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.99",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.86",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.86",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","92.45",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.68",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.10",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.89",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.03",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.77",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.09",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.91",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.86",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.86 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.80",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.14",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.40",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.18",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","760.69",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","328619",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","820.45",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","354435",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7383 fused and 5725 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.62",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.44",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","34540",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.92",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","3.75",
"64","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5410 excessive sectors (21% of the total 25901 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8157",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.92",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.56",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.81",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.90",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2603.01",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.25",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.09",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.09",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.8%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","97.52",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.92",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.30",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.35",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.10",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.95",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.27",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.73",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.83",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.16",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.23",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","28.00",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","774.57",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","334613",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","835.29",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","360844",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7848 fused and 6091 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.94",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.64",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35389",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.88",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.00",
"65","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5643 excessive sectors (21% of the total 27428 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8228",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.90",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.59",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.97",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.65",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.98",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2630.95",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.20",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.85",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.85",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.6%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","96.76",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.90",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.28",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.18",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.89",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.92",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.36",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.64",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.97",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.97 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.88",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.21",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.20",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.97",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","777.10",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","335707",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","837.85",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","361950",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7931 fused and 6157 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.89",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.61",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35544",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.87",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.05",
"66","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5754 excessive sectors (21% of the total 27759 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8176",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.99",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.65",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.50",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.21",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2661.50",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.30",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.61",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.61",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.3%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.23",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.99",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.35",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.96",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.92",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.99",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.14",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.86",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.90",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.90 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.88",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.21",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.16",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.93",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","780.43",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337145",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","841.43",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","363496",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8029 fused and 6239 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.72",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.50",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35748",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.82",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.12",
"67","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5514 excessive sectors (20% of the total 27778 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8321",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.92",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.74",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.94",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.82",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.15",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2653.22",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.20",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.98",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.98",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.34",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.92",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.29",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.43",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.04",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.92",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.13",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.87",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.94",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.94 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.00",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.35",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.09",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.86",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","786.62",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","339821",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","848.39",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366504",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8238 fused and 6403 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.05",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.71",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.1%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36127",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.81",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.23",
"68","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5882 excessive sectors (20% of the total 28770 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8361",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.80",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.56",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.58",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.15",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2653.01",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.07",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.71",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.71",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","99.85",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.80",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.19",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.96",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.92",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.83",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.94",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.06",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.85",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.85 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.92",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.26",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.16",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.93",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","780.43",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337145",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","841.39",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","363482",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8029 fused and 6239 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.61",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.43",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35748",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.82",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.12",
"69","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5468 excessive sectors (20% of the total 27767 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8268",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.04",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.86",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.74",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.20",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2684.47",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.32",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.77",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.77",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","102.92",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.04",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.38",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.24",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.47",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.01",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.77",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.23",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.90",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.90 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.21",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.57",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.05",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.81",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","791.16",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","341783",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","852.93",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","368464",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8386 fused and 6521 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.66",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.46",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36405",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.79",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.31",
"70","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5993 excessive sectors (20% of the total 29324 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8395",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.73",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.43",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.84",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.83",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2611.34",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.99",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.09",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.09",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","98.29",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.73",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.13",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.37",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.77",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.78",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.47",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.53",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.77",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.10",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.20",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.97",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","777.04",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","335681",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","837.90",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","361974",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 7900 fused and 6143 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.04",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.70",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35541",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.79",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.06",
"71","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5448 excessive sectors (20% of the total 27372 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8099",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.10",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.76",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.74",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.73",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.25",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2649.98",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.43",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.86",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.86",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.53",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.10",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.46",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.42",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.34",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.09",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.11",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.89",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.97",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.31",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.13",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.90",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","783.23",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","338357",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","844.29",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364732",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8109 fused and 6307 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.72",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.50",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35920",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.17",
"72","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5671 excessive sectors (20% of the total 28177 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8095",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.09",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.78",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.71",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.39",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2647.75",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.42",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.84",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.84",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","100.05",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.09",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.45",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.87",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","28.57",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.08",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.10",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.90",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.89",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.89 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.87",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.20",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.16",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.92",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","781.93",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337792",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","842.94",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364148",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8064 fused and 6272 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.86",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.59",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35840",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.15",
"73","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5829 excessive sectors (21% of the total 28315 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8179",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.99",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.68",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.90",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.26",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.17",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2695.26",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.31",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.16",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.38",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.29",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.25",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.29",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","98.28",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.99",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.36",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.50",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.22",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.00",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.07",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.93",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.91",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.91 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.98",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.33",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.14",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.91",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","782.19",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","337905",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","843.35",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","364326",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8073 fused and 6279 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.4%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.56",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.04",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.6%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","35856",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.15",
"74","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5656 excessive sectors (20% of the total 28075 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8080",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.15",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.89",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.77",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.31",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2656.79",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.50",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.91",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.91",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","101.56",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.15",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.51",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.21",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.72",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.13",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","31.56",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","68.44",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","10.19",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.66",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.2 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 10.19 active warps per scheduler, but only an average of 0.66 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","32.29",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","34.82",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.10",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.86",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","786.37",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","339713",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","847.88",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366285",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8217 fused and 6391 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.92",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.63",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36112",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.23",
"75","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5936 excessive sectors (21% of the total 28764 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8129",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.16",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.89",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.53",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.24",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2703.40",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.50",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.56",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.56",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.72",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.16",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.51",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.64",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.36",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.13",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.91",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.09",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.88",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.88 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.02",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.36",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.03",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.79",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","791.43",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","341896",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","853.09",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","368534",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8395 fused and 6528 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.76",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.53",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36421",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.79",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.31",
"76","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5809 excessive sectors (20% of the total 29021 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.24",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.12",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8576",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","7.70",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.51",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.88",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","6.89",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2651.86",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","9.90",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.37",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.00",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.00",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.6%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.18",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","7.70",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.09",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.48",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.37",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","6.72",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.22",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.78",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.98",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.98 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.04",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.38",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.10",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.86",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","787.16",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","340052",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","848.52",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","366562",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8244 fused and 6412 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.6%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.38",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.92",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36160",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.24",
"77","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6040 excessive sectors (21% of the total 29046 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8106",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.30",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.09",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.97",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.58",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2693.05",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.64",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.19",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","32.00",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.28",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","32.00",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","104.66",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.30",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.62",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.54",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.79",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.23",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.36",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.64",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.97",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.97 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","29.89",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.22",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.95",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.70",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","799.45",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","345363",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","861.80",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","372298",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8667 fused and 6741 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.68",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.11",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36912",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.46",
"78","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6132 excessive sectors (20% of the total 30180 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8188",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.07",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","6.83",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.71",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.12",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.27",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2857.47",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.39",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.10",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","29.76",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.19",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","29.76",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (21.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","103.02",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.07",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.43",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.21",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.45",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.06",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.18",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.82",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.97",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.97 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.06",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.40",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","28.06",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.83",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 11.0 cycles being stalled waiting for an immediate constant cache (IMC) miss. A read from constant memory costs one memory read from device memory only on a cache miss; otherwise, it just costs one read from the constant cache. Immediate constants are encoded into the SASS instruction as 'c[bank][offset]'. Accesses to different addresses by threads within a warp are serialized, thus the cost scales linearly with the number of unique addresses read by all threads within a warp. As such, the constant cache is best when threads in the same warp access only a few distinct locations. If all threads of a warp access the same location, then constant memory can be as fast as a register access.. This stall type represents about 36.7% of the total average of 30.1 cycles between issuing two instructions."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","788.73",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","340730",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","850.26",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","367313",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8298 fused and 6454 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 34.5%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","64.52",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","41.29",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (64.5%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","36256",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.27",
"79","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 5767 excessive sectors (20% of the total 28779 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8091",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.50",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.46",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.74",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.00",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2777.51",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.83",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.52",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.52",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.0%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","111.57",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.50",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.78",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.51",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.66",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.36",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.03",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.97",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.91",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.91 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.00",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.33",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.81",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.55",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","812.27",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","350900",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","875.44",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","378192",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9108 fused and 7084 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.3%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.71",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.49",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.7%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37696",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.69",
"80","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6300 excessive sectors (20% of the total 31557 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8326",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.14",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.03",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.81",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.83",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","7.43",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2728.92",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.41",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.39",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.74",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.74",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","106.57",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.14",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.46",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.20",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.78",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.07",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.82",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.18",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.22",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.57",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.89",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.64",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","803.64",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","347171",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","866.09",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","374153",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 8811 fused and 6853 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.84",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.58",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37168",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.53",
"81","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6164 excessive sectors (20% of the total 30483 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8063",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.55",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.49",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.65",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.94",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.20",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2760.31",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.89",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.78",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.78",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","112.18",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.55",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.82",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.20",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.32",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.40",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.89",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.11",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.91",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.91 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.12",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.47",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.79",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.54",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","813.84",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","351578",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","877.16",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","378934",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9162 fused and 7126 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.1%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.88",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.60",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.9%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37792",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.71",
"82","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6541 excessive sectors (20% of the total 31954 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8101",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.45",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.39",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.87",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.91",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.16",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2746.92",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.79",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.80",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.80",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.2%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","108.15",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.45",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.74",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.44",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","29.51",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.33",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.01",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.99",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.18",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.53",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.82",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.57",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","810.44",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","350109",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","873.50",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","377350",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9045 fused and 7035 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.18",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.80",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","37584",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.65",
"83","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6240 excessive sectors (20% of the total 31250 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.19",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8216",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.51",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.54",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.68",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.06",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.21",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2788.14",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.81",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.83",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.83",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (23.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","114.57",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.51",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.77",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.18",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.29",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.35",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.08",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.92",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.98",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.98 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.18",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.51",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.68",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.42",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","823.78",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","355872",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","887.59",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","383438",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9504 fused and 7392 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.19",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.80",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38400",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.89",
"84","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6401 excessive sectors (20% of the total 32692 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.17",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.05",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8193",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.50",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.50",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","23.87",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.06",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2914.65",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.80",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.13",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.40",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.34",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.21",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.34",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.1%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","112.23",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.50",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.76",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.13",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.02",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.35",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","33.11",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","66.89",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.99",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.99 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.18",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.53",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.71",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.46",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","820.64",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","354516",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","884.33",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","382029",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9396 fused and 7308 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 35.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","63.78",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.82",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (63.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38208",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.83",
"85","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6322 excessive sectors (20% of the total 32346 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.15",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8130",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.66",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.74",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.84",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.91",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.30",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2824.46",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","10.99",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.41",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.58",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.58",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","113.75",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.66",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","7.91",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.85",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.72",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.47",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.92",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.08",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.92",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.92 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.14",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.47",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.64",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.38",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.1 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 30.2% of the total average of 30.1 cycles between issuing two instructions."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","827.96",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","357680",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","892.10",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","385389",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9648 fused and 7504 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.2%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","61.82",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.57",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (61.8%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","38656",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","4.96",
"86","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6640 excessive sectors (20% of the total 33384 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.16",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.04",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8099",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","8.77",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","7.86",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.78",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.06",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.38",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2833.56",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.11",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.41",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.73",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.73",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.9%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","116.38",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","8.77",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.00",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.97",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","30.73",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.55",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.85",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.15",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.93",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.68",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.93 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.22",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.58",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.58",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","27.32",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.2 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 30.6% of the total average of 30.2 cycles between issuing two instructions."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","833.98",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","360279",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","899.15",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","388434",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 9855 fused and 7665 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.21",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.81",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","39024",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.07",
"87","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 6793 excessive sectors (20% of the total 34163 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.07",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8103",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.26",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.63",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.58",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.15",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","9.26",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2981.44",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.57",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 1% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.43",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.43",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.43",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","130.65",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.26",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.63",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.39",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.38",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.88",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.69",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.31",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.99",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.99 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.56",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.90",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.22",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.93",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.9 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.3% of the total average of 30.6 cycles between issuing two instructions."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","870.60",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","376099",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","937.13",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","404841",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11115 fused and 8645 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.28",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.86",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.3%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41264",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.72",
"88","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7785 excessive sectors (20% of the total 38520 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.20",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.08",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8218",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.07",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.40",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.62",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.36",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.93",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","2936.51",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.35",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.18",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.42",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.75",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.27",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.75",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.7%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","128.64",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.07",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.40",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.93",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.32",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.73",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.8 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.93",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.33",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.07",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.99",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.70",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.0 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.99 active warps per scheduler, but only an average of 0.70 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.34",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","32.66",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.26",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.98",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 9.7 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.1% of the total average of 30.3 cycles between issuing two instructions."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","866.15",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","374178",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","932.24",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","402728",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 10962 fused and 8526 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 36.7%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.36",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.91",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.4%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","40992",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.64",
"89","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7696 excessive sectors (20% of the total 38040 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.14",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.03",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8205",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.27",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.60",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.97",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","24.17",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","9.54",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","3143.40",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.57",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 1% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.12",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.43",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","30.18",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.21",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","30.18",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (21.5%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","125.98",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.27",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.60",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","23.05",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","31.47",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.88",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.27",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.73",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.95",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.95 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.82",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.17",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.08",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.79",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.5 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 34.2% of the total average of 30.8 cycles between issuing two instructions."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","881.59",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","380845",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","948.75",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","409861",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11493 fused and 8939 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 35.8%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","63.22",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","40.46",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (63.2%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41936",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.91",
"90","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7810 excessive sectors (20% of the total 39229 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Frequency","cycle/nsecond","1.18",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Frequency","cycle/nsecond","1.06",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Elapsed Cycles","cycle","8387",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Memory Throughput","%","9.04",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","DRAM Throughput","%","8.38",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Duration","usecond","7.90",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L1/TEX Cache Throughput","%","25.15",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","L2 Cache Throughput","%","8.98",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","SM Active Cycles","cycle","3009.68",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","GPU Speed Of Light Throughput","Compute (SM) Throughput","%","11.29",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight","","","","SOLBottleneck","WRN","This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SpeedOfLight_RooflineChart","","","","SOLFPRoofline","INF","The ratio of peak float (fp32) to double (fp64) performance on this device is 2:1. The kernel achieved  close to 0% of this device's fp32 peak performance and  close to 0% of its fp64 peak performance. See the Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Active","inst/cycle","1.17",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Executed Ipc Elapsed","inst/cycle","0.42",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issue Slots Busy","%","31.43",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","Issued Ipc Active","inst/cycle","1.26",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Compute Workload Analysis","SM Busy","%","31.43",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","ComputeWorkloadAnalysis","","","","HighPipeUtilization","INF","ALU is the highest-utilized pipeline (22.4%) based on active cycles, taking into account the rates of its different instructions. It executes integer and logic operations. It is well-utilized, but should not be a bottleneck."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Memory Throughput","Gbyte/second","126.30",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Busy","%","9.04",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Max Bandwidth","%","8.38",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L1/TEX Hit Rate","%","22.76",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Success Rate","%","0",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Compression Ratio","","0",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","L2 Hit Rate","%","32.09",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Memory Workload Analysis","Mem Pipes Busy","%","7.69",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for loads from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.7 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced loads and try to minimize how many cache lines need to be accessed per memory request."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","MemoryWorkloadAnalysis_Tables","","","","MemoryCacheAccessPattern","WRN","The memory access pattern for stores from L1TEX to L2 is not optimal. The granularity of an L1TEX request to L2 is a 128 byte cache line. That is 4 consecutive 32-byte sectors per L2 request. However, this kernel only accesses an average of 1.0 sectors out of the possible 4 sectors per cache line. Check the Source Counters section for uncoalesced stores and try to minimize how many cache lines need to be accessed per memory request."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","One or More Eligible","%","32.34",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Issued Warp Per Scheduler","","0.32",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","No Eligible","%","67.66",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Active Warps Per Scheduler","warp","9.96",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Scheduler Statistics","Eligible Warps Per Scheduler","warp","0.69",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SchedulerStats","","","","IssueSlotUtilization","WRN","Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only issues an instruction every 3.1 cycles. This might leave hardware resources underutilized and may lead to less optimal performance. Out of the maximum of 16 warps per scheduler, this kernel allocates an average of 9.96 active warps per scheduler, but only an average of 0.69 warps were eligible per cycle. Eligible warps are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible warp results in no instruction being issued and the issue slot remains unused. To increase the number of eligible warps, reduce the time the active warps are stalled by inspecting the top stall reasons on the Warp State Statistics and Source Counters sections."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Issued Instruction","cycle","30.80",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Warp Cycles Per Executed Instruction","cycle","33.14",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Active Threads Per Warp","","27.10",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Warp State Statistics","Avg. Not Predicated Off Threads Per Warp","","26.82",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","WRN","On average, each warp of this kernel spends 10.0 cycles being stalled waiting for a scoreboard dependency on a L1TEX (local, global, surface, texture) operation. Find the instruction producing the data being waited upon to identify the culprit. To reduce the number of cycles waiting on L1TEX data accesses verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit rates by increasing data locality (coalescing), or by changing the cache configuration. Consider moving frequently used data to shared memory.. This stall type represents about 32.5% of the total average of 30.8 cycles between issuing two instructions."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","WarpStateStats","","","","CPIStall","INF","Check the Warp Stall Sampling (All Cycles) table for the top stall locations in your source based on sampling data. The Kernel Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-reference) provides more details on each stall reason."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Executed Instructions Per Scheduler","inst","878.97",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Executed Instructions","inst","379715",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Avg. Issued Instructions Per Scheduler","inst","945.91",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Instruction Statistics","Issued Instructions","inst","408632",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","InstructionStats","","","","FPInstructions","WRN","This kernel executes 11403 fused and 8869 non-fused FP64 instructions. By converting pairs of non-fused instructions to their fused (https://docs.nvidia.com/cuda/floating-point/#cuda-and-floating-point), higher-throughput equivalent, the achieved FP64 performance could be increased by up to 22% (relative to its current performance). Check the Source page to identify where this kernel executes FP64 instructions."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Block Size","","672",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Function Cache Configuration","","CachePreferL1",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Grid Size","","1024",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Registers Per Thread","register/thread","32",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Shared Memory Configuration Size","Kbyte","16.38",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Driver Shared Memory Per Block","Kbyte/block","1.02",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Dynamic Shared Memory Per Block","byte/block","0",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Static Shared Memory Per Block","byte/block","0",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Threads","thread","688128",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Launch Statistics","Waves Per SM","","3.16",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","LaunchStats","","","","LaunchConfiguration","WRN","A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 51 thread blocks. Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for up to 25.0% of the total kernel runtime with a lower occupancy of 37.0%. Try launching a grid with no partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for a grid. See the Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more details on launch configurations."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit SM","block","32",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Registers","block","3",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Shared Mem","block","16",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Block Limit Warps","block","3",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Active Warps per SM","warp","63",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Theoretical Occupancy","%","98.44",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Occupancy","%","62.05",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","Achieved Active Warps Per SM","warp","39.71",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Occupancy","","","","Occupancy","WRN","This kernel's theoretical occupancy (98.4%) is limited by the number of required registers. This kernel's theoretical occupancy (98.4%) is limited by the number of warps within each block. The difference between calculated theoretical (98.4%) and measured achieved occupancy (62.0%) can be the result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on optimizing occupancy."
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions Ratio","%","0.11",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Instructions","inst","41776",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Branch Efficiency","%","77.78",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","Source Counters","Avg. Divergent Branches","","5.87",
"91","3228115","hpcg_bench","127.0.0.1","void amgx::multicolor_gauss_seidel_solver::multicolorGSSmoothCsrKernel_nPerRow<int, double, double, (int)672, (int)32, (int)32>(const T1 *, const T1 *, const T1 *, const T2 *, const T2 *, const T3 *, const T3 *, T3, const int *, int, int, T3 *)","1","7","(672, 1, 1)","(1024, 1, 1)","0","8.0","SourceCounters","","","","UncoalescedGlobalAccess","WRN","This kernel has uncoalesced global accesses resulting in a total of 7785 excessive sectors (20% of the total 38969 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source locations. The CUDA Programming Guide (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional information on reducing uncoalesced device memory accesses."
